{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85089af8",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "A real world problem that can be formulated as an MDP is deciding at what age it is more worthwhile to repair or replace a car. The state space for this problem consists of all the ages and anticipated repair costs of the car. The action space is comprised of two choices: to repair or replace the car. For simplicity, we assume that if the car is replaced, its replacement is a new car rather than a used one, though this problem could also apply with used cars. This way, in the transition model, replacing the car will \"reset\" its age back to zero and there will be a higher probability of moving to a state with a lower repair cost, as newer cars tend to need less repair. Alternatively, choosing to repair the car means that its age will increase and there will be a higher probability of moving to a state with a higher repair cost. Reward can be represented as money saved by choosing to repair the car. The reward of buying a new car would serve as the baseline, with a value of 0. The reward for repairing the car then, would be equal to the cost of buying a new car minus the cost of repairing it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6df2f90",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "In healthcare, performing autonomous surgeries can reduce the number of tedious routines that would otherwise need to be handled by surgeons. Overall this reduces surgeon’s fatigue and increases the number of procedures a surgeon can undertake in a given time. Currently, learning-based methods of training medical robots have achieved considerable performance for dexterous manipulation. But, these learning-based simulations have limited scenarios and simplified physical interactions, hindering the real-world performance of learned policies.\n",
    "\n",
    "There have been several attempts to use reinforcement learning for surgical robot learning, one of which is SurRol, aptly named after Surgical Robot Learning. Reinforcement learning has the advantage of allowing for task generalization and improving performance when compared to controllers designed for specific subtasks. It also results in lower-cost data collection compared to learning-based methods. SurRol is an open-source RL-centered simulation platform that is compatible with the da Vinci Research Kit (dVRK) and built from open-source PyBullet. SurRol integrates a reinforcement library for algorithm development with a real-time physics engine producing more realistic physical interactions while being able to support more patient side manipulator and endoscopic camera manipulator scenarios, which are common tasks in real autonomous surgical execution. \n",
    "\n",
    "To build their platform for surgical robot learning, SurRol researchers created an RL library for agents to interact with. To do this, they formulated the manipulation problem into the Markov Decision Process. Their state space refers to the position of the robot and an array of different task-specific observations. The action space consists of six degrees of freedom of motion. For patient side manipulator tasks the action space was limited to dx, dy, dz, dyaw/dpitch, and j, where j refers to whether the jaw of the robot is open or closed, in order to focus on rotation within a plane for these tasks. The action space for endoscopic camera manipulator tasks was restricted to Cartesian-space position control and the velocity of the camera in its own frame or the roll angle control droll when the observation is in the camera space. Additionally, SurRol supports two observation methods that comprise the observation space. One is the low-dimensional ground-truth states, such as 3D Cartesian positions, which allows the agents to focus on continuous control learning. The other is high-dimensional RGB, depth, mask images rendered by OpenGL, which is essential in robotic control. SurRol’s tasks are primarily goal-based in which the agent receives a binary reward. The exception to this is the endoscopic camera manipulator continuous tracking task, where the tracked object is constantly moving. To address this, the researchers devised a dense function to encourage the agent to follow the target. After developing their RL library, the researchers constructed the dVRK robots and surgical contents from the physics engine and built in ten surgical learning-based tasks for algorithm development and execution. After testing SurRol, it was found that it has better overall transferability to the real world than previously developed learning-based models or specifically-designed controllers.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
